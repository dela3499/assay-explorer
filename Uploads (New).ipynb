{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import toolz as tz\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Level Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_files(path): \n",
    "    \"\"\" ----------------\n",
    "        String -> String\n",
    "        ----------------\n",
    "        Given path to uploaded files, check necessary\n",
    "        files are present. Return error string ('' if no errors.)\n",
    "    \n",
    "    \"\"\"\n",
    "    to_path = lambda f: os.path.join(path, f)\n",
    "    exists = lambda f: os.path.exists(to_path(f))\n",
    "    nonempty = lambda f: len(os.listdir(to_path(f))) > 0\n",
    "    checks = \\\n",
    "        [(exists('metadata.csv'), \"File missing: metadata.csv\"),\n",
    "         (exists('Plates/'), \"Folder missing: Plates\"),\n",
    "         (exists('Layouts/'), \"Folder missing: Layouts\"),\n",
    "         (nonempty('Plates/'), \"It looks like you haven't got any plates in your Plates folder.\"),\n",
    "         (nonempty('Layouts/'), \"It looks like you haven't got any layouts in your Layouts folder.\")]\n",
    "    \n",
    "    return '\\n'.join([string for boolean, string in checks if boolean == False])\n",
    "\n",
    "def unzip(zipped_path, unzipped_path):\n",
    "    \"\"\" ------------------------------------------\n",
    "        String -> String -> SideEffect(FileSystem)\n",
    "        ------------------------------------------\n",
    "        Given path to zipped file, unzip and write to \n",
    "        unzipped path. \n",
    "    \"\"\"\n",
    "     # clear out existing files\n",
    "    if os.path.exists(unzipped_path):\n",
    "        shutil.rmtree(unzipped_path)\n",
    "    \n",
    "    # Unzip\n",
    "    with zipfile.ZipFile(zipped_path, \"r\") as z:\n",
    "        z.extractall(unzipped_path)\n",
    "        \n",
    "def get_plate_data(path):\n",
    "    \"\"\" -------------------\n",
    "        String -> DataFrame\n",
    "        -------------------\n",
    "        Get plate data, drop empty columns, drop selected columns, \n",
    "        rename columns.\n",
    "    \"\"\"\n",
    "    delimiter = '\\t',\n",
    "    skiprows = 4,\n",
    "    dropcols = ['Laser focus score',\n",
    "                '\\.[0-9]*\\Z'],\n",
    "\n",
    "    def rename_column(col):\n",
    "        \"\"\" Rename column col to remove whitespace, backslashes, prefixes,\n",
    "            and suffixes (esp. large parenthetic suffix). \"\"\"\n",
    "        if col.startswith('Cell:'):\n",
    "            return col.split('(')[0].lstrip(\"Cell:\").rstrip('/').strip(' ')\n",
    "        else:\n",
    "            return col.split('(')[0].rstrip('/').strip(' ')\n",
    "    \n",
    "    return thread_first(path,\n",
    "                        from_file,\n",
    "                        (str.replace,'\\r',''),\n",
    "                        StringIO,\n",
    "                        pd.read_csv(delimiter = delimiter, skiprows = skiprows),\n",
    "                        df.dropna(axis = 1, how = 'all'),\n",
    "                        (drop_matching_columns, dropcols),\n",
    "                        df.rename(columns = rename_column))\n",
    "\n",
    "def gather_plate_data(plate_metadata):\n",
    "    \"\"\" -------------------\n",
    "        Series -> DataFrame\n",
    "        -------------------\n",
    "        Given paths to plate and layout files, \n",
    "        combine their contents into one dataframe. \n",
    "    \"\"\"\n",
    "    plate_path = os.path.join(unzipped_path, 'Plates', plate_metadata['Plate File'])\n",
    "    plate_data = get_plate_data(plate_path, plate_import_config)\n",
    "    \n",
    "    layout_path = os.path.join(unzipped_path, 'Layouts', plate_metadata['Layout File'])\n",
    "    layout_data = get_layout_data(plate_path, plate_import_config)\n",
    "    \n",
    "    generate_condition_string = lambda series: ' '.join([str(x) for x in series.values[1:]])\n",
    "    layout_data['Condition'] = layout_data.apply(generate_condition_string, axis = 1)\n",
    "\n",
    "    return tz.thread_first(\n",
    "        pd.merge(plate_data, layout_data, on = 'Well Name'),\n",
    "        (add_dict_to_dataframe, dict(plate_metadata))) # add all plate metadata to final dataframe\n",
    "\n",
    "def get_layout_data(path):\n",
    "    \"\"\" -------------------\n",
    "        String -> DataFrame\n",
    "        -------------------\n",
    "        Given a path to a file with proper format (see below), return a dataframe \n",
    "        with 'Well Name' column and additional columns for each provided parameter.\n",
    "        \n",
    "        Format: Parameter Name, 1, 2 ...\n",
    "                A, Value, Value ...\n",
    "                B, Value, Value ...\n",
    "        Notes: '\\r' is present in csv output on windows (or google docs) and can confuse pandas `read_csv` function.\n",
    "               Algorithm partitions by whether row is empty (each section of data should be separated by a blank line), \n",
    "                 then filters out groups where row is empty (text of row contains only commas).\n",
    "                ...   \n",
    "        \"\"\"\n",
    "    return tz.thread_last(\n",
    "        path,\n",
    "        from_file,\n",
    "        split_on_newlines,\n",
    "        (map, lambda line: line.rstrip(',')),\n",
    "        (tz.partitionby, lambda s: s == ''),\n",
    "        (filter, lambda group: not string_is_empty(group[0])),\n",
    "        (filter, lambda group: group[0] != ''),\n",
    "        (map, lambda strings: pd.read_csv(StringIO(str.join('\\n', strings)))),\n",
    "        (map, parse_label_group),\n",
    "        (reduce, lambda left, right: pd.merge(left, right, on = 'Well Name')))\n",
    "\n",
    "get_metadata = lambda f: drop_empty(pd.read_csv(f))\n",
    "\n",
    "def parse_label_group(df):\n",
    "    \"\"\" -------------------------------------------\n",
    "        DataFrame -> DataFrame['Well Name', Parameter]\n",
    "        -------------------------------------------\n",
    "        Takes string containing all data for one field, and creates a \n",
    "        tidy dataframe with two columns: 'Well Name', and field. \n",
    "    \"\"\"\n",
    "    letters = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "    label_name = df.columns[0]\n",
    "    return tz.thread_last(\n",
    "        df.values[:,1:],\n",
    "        lambda values: pd.DataFrame(values, columns = map(lambda num: stringify(num,2), range(1,values.shape[1] + 1))),\n",
    "        lambda dataframe: add_col(dataframe, 'Row', pd.Series(letters[:len(dataframe)])),\n",
    "        lambda dataframe: pd.melt(dataframe, id_vars=['Row']),\n",
    "        lambda dataframe: add_col(dataframe,'Well Name', dataframe['Row'] + dataframe['variable']),\n",
    "        lambda dataframe: dataframe.drop(['Row','variable'], axis=1),\n",
    "        lambda dataframe: dataframe.rename(columns={'value': label_name}),\n",
    "        lambda dataframe: dataframe[['Well Name', label_name]]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_on_newlines(string):\n",
    "    \"\"\" ---------------------\n",
    "        String -> List String\n",
    "        ---------------------\n",
    "        Given a string which may contain \\r, \\n, or both, \n",
    "        split on newlines so neither character is present in output. \n",
    "    \"\"\"\n",
    "    r = '\\r' in string\n",
    "    n = '\\n' in string\n",
    "    \n",
    "    if r and n: \n",
    "        return string.replace('\\r','').split('\\n')\n",
    "    elif r:\n",
    "        return string.split('\\r')\n",
    "    else:\n",
    "        return string.split('\\n')\n",
    "\n",
    "def add_dict_to_dataframe(dataframe, my_dict):\n",
    "    \"\"\" ----------------------------------\n",
    "        DataFrame -> Dict a b -> DataFrame\n",
    "        ----------------------------------\n",
    "        Return dataframe with new column for each key-value pair.\n",
    "        Values are repeated for all rows in a given column. \"\"\"\n",
    "    d = dataframe.copy()\n",
    "    for k, v in my_dict.iteritems():\n",
    "        d[k] = v\n",
    "    return d\n",
    "\n",
    "def matches_any_pattern(s,patterns):\n",
    "    \"\"\" -------------------------------\n",
    "        String -> List Regex -> Boolean\n",
    "        -------------------------------\n",
    "        Return True if any of the patterns matches string s. \n",
    "    \"\"\"\n",
    "    return any([re.search(pattern,s) for pattern in patterns])\n",
    "\n",
    "def drop_matching_columns(df,patterns):\n",
    "    \"\"\" ----------------------\n",
    "        DataFrame -> DataFrame\n",
    "        ----------------------\n",
    "        Drop columns from dataframe if they match any pattern.\n",
    "    \"\"\"\n",
    "    matching_columns = [col for col in df.columns\n",
    "                            if matches_any_pattern(col,patterns)]\n",
    "    return df.drop(matching_columns,axis=1)\n",
    "\n",
    "drop_empty = lambda df: df.dropna(how='all',axis=0).dropna(how='all',axis=1)    \n",
    "\n",
    "def from_file(filename):\n",
    "    \"\"\" ----------------\n",
    "        String -> String\n",
    "        ----------------\n",
    "        Return contents of selected file.\n",
    "    \"\"\"\n",
    "    f = open(filename)\n",
    "    data = f.read()\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "def add_col(dataframe, colname, values):\n",
    "    \"\"\" --------------------------------------------\n",
    "        DataFrame -> String -> (a | [a] | Series[a])\n",
    "        --------------------------------------------\n",
    "        Add column to dataframe with given values.\n",
    "    \"\"\"\n",
    "    dataframe[colname] = values\n",
    "    return dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/home/ubuntu/assay-explorer/data/07-20-2015-2016-04-23.zip'\n",
    "unzip_path = '/home/ubuntu/assay-explorer/data/unzipped/'\n",
    "meta_path = '/home/ubuntu/assay-explorer/data/unzipped/07-20-2015/metadata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unzip(data_path, unzip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_files('/home/ubuntu/assay-explorer/data/unzipped/07-20-2015/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meta = get_metadata(meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = thread_last(\n",
    "    metadata,\n",
    "    (maprows,gather_plate_data),\n",
    "    pd.concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
